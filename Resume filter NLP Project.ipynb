{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "014b1d95",
   "metadata": {},
   "source": [
    "# NLP Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea2326",
   "metadata": {},
   "source": [
    "## Resume Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc49cb",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6915a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.spatial.distance import euclidean\n",
    "import io\n",
    "import PyPDF2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import docx2txt \n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pathlib\n",
    "import os\n",
    "import spacy\n",
    "import pdfminer\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "import ocrmypdf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf889f6",
   "metadata": {},
   "source": [
    "### Importing Trained Model (Trained on ------ > Kaggle Resume Dataset )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085371bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = pickle.load(open('svc_model','rb'))\n",
    "word_vectorizer = pickle.load(open('word_vectorizer','rb'))\n",
    "enc = pickle.load(open('Label_encoder','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c236b7",
   "metadata": {},
   "source": [
    "#### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba1b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f7e27",
   "metadata": {},
   "source": [
    "####  Text Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b035a84",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    resource_manager = PDFResourceManager()\n",
    "    output_string = io.StringIO()\n",
    "    converter = TextConverter(resource_manager, output_string)\n",
    "    interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        for page in PDFPage.get_pages(pdf_file):\n",
    "            try:\n",
    "                interpreter.process_page(page)\n",
    "            except pdfminer.pdfparser.PDFSyntaxError:\n",
    "                ocrmypdf.ocr(pdf_path, pdf_path,redo_ocr=True)\n",
    "                interpreter.process_page(page)\n",
    "    text = output_string.getvalue()\n",
    "    output_string.close()\n",
    "    converter.close()\n",
    "    text = str(text.replace('\\n','\\t')).replace('\\t',' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "def extract_text_from_doc(doc):\n",
    "    text = docx2txt.process(doc)\n",
    "    text = str(text.replace('\\n','\\t')).replace('\\t',' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ff43d1",
   "metadata": {},
   "source": [
    "#### Category Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9a5439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category(text):\n",
    "    category = enc.inverse_transform(svc.predict(word_vectorizer.transform([text])))[0]\n",
    "    return category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a00ed62",
   "metadata": {},
   "source": [
    "#### Details Extration Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a08dd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applicant_name(docx):\n",
    "    person_names = []\n",
    "    for ent in docx.ents:\n",
    "        if ent.label_ == 'PERSON':\n",
    "            person_names.append(ent.text)\n",
    "    return person_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bfc1022",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def phone_extract(docx):\n",
    "    phone_numbers = []\n",
    "    for token in docx:\n",
    "        if token.like_num and len(token.text) >= 10:\n",
    "            phone_numbers.append(token.text)\n",
    "    if phone_numbers!=[]:\n",
    "        return phone_numbers[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f09b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skills_extract(docx):\n",
    "    skills = []\n",
    "    for ent in docx.ents:\n",
    "        if ent.label_ == \"SKILL\":\n",
    "            skills.append(ent.text)\n",
    "            return skills    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b704794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_experience(text):\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"DATE\":\n",
    "            if \"year\" in ent.text.lower():\n",
    "                return ent.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8659fb47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "088dff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_score(resume,Job_desc):\n",
    "    ## Co simmilarity\n",
    "    \n",
    "    stop_words = list(spacy.lang.en.stop_words.STOP_WORDS)\n",
    "    resume = nlp(resume)\n",
    "    Job_desc = nlp(job)\n",
    "    resume_filtered = [token.text for token in resume if token.is_alpha]\n",
    "    Job_desc_filtered = [token.text for token in Job_desc if token.is_alpha]\n",
    "    resume_filtered =[i.lower() for i in resume_filtered]\n",
    "    Job_desc_filtered = [i.lower() for i in Job_desc_filtered]\n",
    "    resume_filtered= ' '.join(resume_filtered)\n",
    "    Job_desc_filtered= ' '.join(Job_desc_filtered)\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True,stop_words=stop_words)\n",
    "    vectorizer.fit([Job_desc_filtered])\n",
    "    J_vector = vectorizer.transform([Job_desc_filtered])\n",
    "    R_vector = vectorizer.transform([resume_filtered])\n",
    "    similarity_score = cosine_similarity(J_vector,R_vector)[0][0]*100\n",
    "    \n",
    "    ## Euclidean distance\n",
    "    J_vector_array = J_vector.toarray().ravel()\n",
    "    R_vector_array = R_vector.toarray().ravel()\n",
    "    euclidean_distance = euclidean(J_vector_array, R_vector_array)*100\n",
    "    \n",
    "    ## User Category\n",
    "    user_category = category(resume_filtered)\n",
    "    \n",
    "    ## Job vs User category score\n",
    "    job_category = category(Job_desc_filtered)\n",
    "    category_match_score = 1 if job_category == user_category else 0\n",
    "    \n",
    "    ## Skills Scores\n",
    "    skills_score = len(skills_extract(resume)) if skills_extract(resume) else 0 ##Spacy en_core_web_sm not able to detect skills \n",
    "    \n",
    "    ## Experience Score\n",
    "    experience_score = len(extract_experience(resume)) if extract_experience(resume) else 0\n",
    "    ## Give a weights to each one\n",
    "    ## w1-->cosimilarity 50%\n",
    "    ## w2-->euclidean_distance 35%, w3-->category_match_score 5%, w4-->skills scores 5%, \n",
    "    ## w5-->Experience scores 5%\n",
    "    \n",
    "    w1=0.45\n",
    "    w2=0.45\n",
    "    w3=0.05\n",
    "    w4=0.025\n",
    "    w5=0.025\n",
    "    total_scores = (w1*similarity_score)+(w2*euclidean_distance)+(w3*category_match_score)+(w4*skills_score)+(w5*experience_score)\n",
    "    if (total_scores >= 60):\n",
    "        result = 'PASS'\n",
    "    else:\n",
    "        result = 'FAIL'\n",
    "    return f'RESULT {result}', f'User Category: {user_category}.',f'co similarity:{similarity_score}%',f'E_distance score {euclidean_distance}', f\"Skills score {skills_score}\", f'Experience scores {experience_score}',f'Total Resume Score {total_scores}'   \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "406b8321",
   "metadata": {},
   "outputs": [],
   "source": [
    "job='''machine learning, data science, pandas  , numpy, sql, deep learning, computer vision , data visualisation , python '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "089cea75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'User Category: Data Science.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_score(extract_text_from_pdf('CV.pdf'),job)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e080e23f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
